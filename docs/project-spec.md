# Voice-clone-Qwen3-TTS 開発前ドキュメント（完全版）

AI-DLCメタデータに基づく開発前ドキュメント。プロジェクト始動プロンプトとParplexityとの壁打ちの内容を統合した完全版。

---

## 0. AI-DLCメタデータ

### プロジェクトパスウェイ

- タイプ：**☑ 新規開発**

### 複雑度評価

- 要求の複雑度：**低**（個人用ボイスクローン→Discord統合という明確な要求）
- 技術的新規性：**高**（Qwen3-TTSは2026年1月公開。開発者は過去にStyleTTS2やESPNet2でモデル構築を試みたが成功していない）
- ステークホルダー数：**1名**（開発者個人のみ）

### 推奨フェーズと深さ

- Inception（要求・要件定義）：**簡易**
- Construction（設計・実装）：**標準**
- Operations（テスト・運用）：**詳細**（Discordサーバーでの読み上げボットとして継続使用するため）

### プロジェクトタイプ別の推奨ステップ

- **新規機能開発**：要求定義 → 要件定義 → 設計 → 実装 → テスト

---

## 1. 要求定義（Why / 誰のため / 何のため）

### 目的・背景

最新のQwen3-TTS（2026年1月公開）を用いて、自分の声をクローンしたTTSモデルを構築する。最終的には、Discord上でテキストメッセージを自分の声で読み上げるボットを実現し、配信・ゲームプレイ時のコミュニケーションツールとして活用する。

### 想定ユーザー・利用シーン

1. **主要シーン**：Discord上で友人とボイスチャット中、タイピングしたメッセージを自分の声で読み上げる
2. 配信中にリアルタイムで音声を出さずに、テキスト→自分の声で読み上げ
3. ゲーム実況やマインクラフト配信中のコメント応答
4. 研究用途：TTS音声品質の評価・実験

### 成功条件（KPI / 目標）

1. **ゴール1達成**：自分の音声サンプル（サンプルボイスの時間制限は設けない）から、認識可能な品質のボイスクローンモデルを作成できる。良品質なボイスクローンモデルを作成することが目的。
2. **ゴール2達成**：Discord botが日本語・英語のテキストメッセージを受け取り、クローンした声で音声出力できる
3. **音声品質**：友人・配信視聴者が「本人の声」と認識できるレベル（主観評価）
4. **レイテンシ**：メッセージ受信から音声出力まで10秒以内（リアルタイム性）

### スコープ

#### 今回やること

1. Qwen3-TTS環境構築（日本語フォーク版、または公式版）
2. 自分の音声サンプル録音（日本語、英語）
3. ボイスクローンモデルの生成とテスト
4. **複数話者・声プロファイルの管理**（フラット構造 + メタデータ CSV/JSON）
5. **話者選択機能**（CLI ツール）
6. **任意テキストでのテスト合成機能**
7. Discord bot基本実装（テキスト→TTS→音声再生）
8. Windows/WSL2環境での動作確認

#### 今回やらないこと

1. リアルタイム音声変換（STT→TTS のライブ変換）
3. 感情制御・抑揚の細かい調整（基本品質で十分。今回成功したら次フェーズで実施）
4. 本番環境への公開デプロイ（ローカル/開発環境のみ）
5. 他のTTSモデルとの比較実験

#### 用語の明確化

- **モデル** = Qwen3-TTS Base model（固定、Hugging Face からロード）。個人の声情報はモデルファイルとして保存しない。
- **声プロファイル** = 参照音声（ref_audio）+ 書き起こしテキスト（ref_text）のセット。声プロファイルは `.pth` 等のモデルファイルとしては保存せず、**音声ファイル + メタデータ**として管理する。

#### Discord 実装時のレイテンシ対策

- **フェーズ1**: 声プロファイル管理 + モデル・参照音声のメモリキャッシュで実装し、レイテンシを抑える。
- **フェーズ2（将来検討）**: レイテンシが問題になった場合、ファインチューニングやその他の最適化を検討する。

### コンテキスト管理

- **このフェーズの成果物保存場所**：`docs/project-spec.md`
- **次フェーズへの引き継ぎ事項**：要求定義スコープを要件定義・設計に含める

---

## 2. 要件定義（AI駆動前提の拡張版）

### 深さレベルの決定

- **ボイスクローン機能【標準】**：論理設計まで
- **Discord bot統合【標準】**：論理設計まで
- **音声品質評価【簡易】**：主観評価のみ

### 2.1 従来型の基本ブロック

#### 機能要件

**主要機能一覧**

1. **音声サンプル録音機能**：NowSmart Audio Recorderにて録音。あらかじめ読み上げるコーパスを用意しておき、それを読み上げることとする。MP3形式で保存。
2. **ボイスクローン生成機能**：Qwen3-TTS Base モデルで自分の声をクローン
3. **TTS生成機能**：日本語・英語テキスト→クローン音声のWAV生成
4. **Discord bot基本機能**：スラッシュコマンドを組み込み、スラッシュコマンドを打ったボイスチャットのVCにボットを入れ、そのチャットで送信されたメッセージを読み上げる
5. **音声品質確認機能**：生成音声のローカル再生・確認

**ユーザーストーリー（概要）**

- ユーザーは自分の声を録音し、ボイスクローンモデルを生成できる
- ユーザーは日本語・英語のテキストを入力し、クローン音声で読み上げることができる
- ユーザーはDiscordのVCに参加し、スラッシュコマンドでボットを招待できる
- ユーザーはチャットに送信したメッセージを、自分の声でVCで読み上げてもらえる

#### 非機能要件

- **パフォーマンス**：メッセージ受信から音声出力まで10秒以内
- **セキュリティ**：Discord token管理、API key管理を厳格に行う
- **可用性**：個人サーバーでの継続運用を想定
- **拡張性**：将来的な感情制御・抑揚調整への対応を見据えた設計

#### 技術要件

- **TTS基盤**：Qwen3-TTS-12Hz-1.7B-Base (Hugging Face)
- **音声処理**：NowSmart Audio Recorderで録音、あらかじめ読み上げるコーパスを用意
- **Discord統合**：discord.py (Python)
- **実行環境**：
  - WSL2/Ubuntu 24.04（優先）
  - CUDA 12.1、PyTorch 2.0+
  - RTX 4070 Ti (12GB VRAM)
  - メインメモリ 64GB
  - 13th Gen Intel Core i7-13700F

#### 制約条件

- **リソース**：RTX 4070 Ti 12GB VRAMの範囲内で動作
- **期間**：個人プロジェクトのため柔軟に対応
- **ビジネス制約**：個人利用のみ

#### リスクと対応方針

1. **VRAM不足**（12GB超過）→ 0.6Bモデルへのフォールバック、FlashAttention導入
2. **音声品質が低い**→ 参照音声の再録音（10〜30秒に延長、ノイズ除去）
3. **Discord bot遅延**→ 非同期処理、キャッシング導入
4. **日本語認識精度が低い**→ 参照テキストの手動修正、faster-whisperモデルサイズ変更

### 2.2 AI駆動開発の5つの問い

#### (1) Why：なぜAIを使うのか？

- 開発速度向上（TTS/Discord API実装の効率化）
- 技術知識の補完（Discord bot/音声処理の未経験部分）
- コード品質向上（ベストプラクティスの適用）
- **重要**：AI駆動開発における開発順序の確立の模索（ドキュメントを揃え、実装の流れ）

#### (2) What：AIが担うのは何か？

**AIが担当する領域**

- Discord bot boilerplateコード生成
- Qwen3-TTS API呼び出しコード生成
- エラーハンドリング・ログ実装
- ドキュメント下書き

**人間（開発者）が必ず判断する領域**

- 音声サンプルの品質評価
- ボイスクローンの主観的品質判断
- Discord bot の運用ルール（どのサーバーで使うか等）
- セキュリティ（Discord token管理、API key管理）

**協働が必要な領域**

- アーキテクチャ設計（モジュール分割）
- パフォーマンス最適化（VRAM使用量、レイテンシ）
- 音声パラメータ調整（sampling rate、品質設定）

**重要**：実装した内容やその結果などをlogで残すこと。Cursorがアクションを取るたびに、logを追加する。

#### (3) How：どう管理・運用するか？

**バージョン管理とAIコードのトレース方法**

- **Gitリポジトリ名**：Voice-clone-Qwen3-TTS
- **AI生成コードのコミットルール**：`[AI] 機能名`
- **コンテキスト保存場所**：`docs/`ディレクトリ

**品質管理**

- **AI生成コードのレビュー基準**：
  1. CUDA/PyTorchエラーハンドリングの確認
  2. Discord API rate limit対応
  3. 音声ファイルのクリーンアップ（一時ファイル削除）

**知識管理**

- 良かったプロンプト・対話パターンは `docs/prompts.md` に記録
- AIとのやりとりから得た学びは `docs/learnings.md` に記録

**成果物の永続化ルール**

- 前フェーズの成果物を次フェーズで活用（要求定義のスコープを要件定義のプロンプトに含める）
- セッション間の継続性：AIが過去のコンテキストにアクセスできる仕組み（ファイル、リンク等）

#### (4) What-if：不確実性/失敗にどう備えるか？

**AIがミスったときの共通ルール**

- 重要機能は必ず開発者がコードを読み直す
- いきなり大きな機能を任せず、小さい単位で検証する

**想定する失敗パターンと対策**

1. **VRAM不足**（12GB超過）→ 0.6Bモデルへのフォールバック、FlashAttention導入
2. **音声品質が低い**→ 参照音声の再録音（10〜30秒に延長、ノイズ除去）
3. **Discord bot遅延**→ 非同期処理、キャッシング導入
4. **日本語認識精度が低い**→ 参照テキストの手動修正、faster-whisperモデルサイズ変更

#### (5) Who：誰が、いつ検証するか？

- **検証者**：開発者自身
- **Mobレビュー**：不要（必要なら友人に音声品質を聞いてもらう）
- **レビュー記録**：Git commit message + `docs/reviews.md`

### コンテキスト管理

- **このフェーズの成果物保存場所**：`docs/project-spec.md`
- **次フェーズへの引き継ぎ事項**：要件定義を設計・実装計画に反映

---

## 3. 役割分担と品質基準

### 役割分担

- **CEO（開発者）**：最終意思決定、品質評価
- **部長（Perplexity）**：アイデアの壁打ち、技術相談
- **部下（Cursor）**：実装、ドキュメント作成、提案

### コミュニケーションルール

- 不明点や判断が必要な点は、開発者に質問すること
- 実装の選択肢が複数ある場合は、推奨案を提示した上で開発者の判断を仰ぐこと
- すべてのアクションをログに記録すること

### 品質基準

- コードはPEP 8準拠
- 適切なエラーハンドリング
- 十分なコメント（日本語可）
- 型ヒント（Type Hints）の使用

---

## 参考資料

- プロジェクト始動プロンプト：`プロジェクト始動プロンプト.md`
- Parplexityとの壁打ち：`Parplexityとの壁打ち.md`
- 開発前ドキュメントテンプレート（AI-DLC対応版）：`開発前ドキュメントテンプレート_AI-DLC対応版.txt`
- Qwen3-TTS：https://qiita.com/GeneLab_999/items/79d8020799c6f9e329dc
